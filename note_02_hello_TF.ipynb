{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"note_02_hello_TF.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"lkPEFHPPN5Uo","colab_type":"text"},"cell_type":"markdown","source":["<div align=\"right\">Naoaki ONO, Shigehiko KANAYA <br/>\n","NAIST DSC</div>"]},{"metadata":{"id":"ECN2Rqg_B_wD","colab_type":"text"},"cell_type":"markdown","source":["[Open in Google Colaboratory](https://colab.research.google.com/github/naono-git/colaboratory/blob/master/note_02_hello_TF.ipynb)"]},{"metadata":{"id":"RQkanKidOCZx","colab_type":"text"},"cell_type":"markdown","source":["# はじめてのTensorFlow\n","\n"]},{"metadata":{"id":"u877T4hTOgR9","colab_type":"text"},"cell_type":"markdown","source":["[TensorFlow](https://www.tensorflow.org/)はGoogleが主導になってオープンソースで開発が進められている深層学習のためのPythonライブラリです。\n","\n","自分でゼロからインストールしようとするとそれなりに手間がかかりますが、幸いColaboratoryでは最新版がインストールされた環境が整えられています。\n","\n","現在のバージョンは下記の変数で確認できます。"]},{"metadata":{"id":"vgxlIAuOOHvX","colab_type":"code","outputId":"84029e52-84fd-4dca-eb2d-5347b36667d2","executionInfo":{"status":"ok","timestamp":1551320932530,"user_tz":-540,"elapsed":662,"user":{"displayName":"Naoaki ONO","photoUrl":"https://lh4.googleusercontent.com/-noyv8C6AI_A/AAAAAAAAAAI/AAAAAAAAAEo/YuSJL9LtK-0/s64/photo.jpg","userId":"13379272366422381316"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["1.13.1\n"],"name":"stdout"}]},{"metadata":{"id":"CdYXDlvRQq-A","colab_type":"text"},"cell_type":"markdown","source":["## Define and Run\n","\n","Pythonは本来「インタプリタ型」言語ですのでプログラムは逐次的に実行されるのですが、そのままだと最適化ができないため計算速度が遅くなるという問題があります。\n","\n","TensorFlowでは計算の高速化のため「はじめにニューラルネットワークの計算手順を全部定義しておき、最適化した後に計算する」という手法をとっています。先に計算を定義するので\"Define-and-run\"モデルと呼ばれています。\n","\n","プログラミングに若干手間がかかる代わり、自動的にGPUに最適化して高速に計算してくれます。\n","\n","（\"Define-and-run\"に対して、Chainer, PyTorchなどのライブラリのように、入力データに対して動的にネットワークを構築していくことができる\"Define-by-run\"と呼ばれるモデルも開発されています。TensorFlowもバージョン2.0ではこれに対応するとの噂です）\n","\n","\n"]},{"metadata":{"id":"YceAz1D-nlZ9","colab_type":"text"},"cell_type":"markdown","source":["試しに「100次元のベクトルに100x100の行列を掛け、得られたベクトルを平均する、という計算を100万回繰り返す」のにかかる時間を測ってみましょう。\n","\n","先に乱数でデータを作っておきます。"]},{"metadata":{"id":"CGC0GjfKONbb","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","\n","nd = 100\n","nn = 1000000\n","xxx = np.reshape(np.random.normal(10, 1, nd*nn), (nn,nd))\n","www = np.reshape(np.random.normal(0, 1, nd*nd), (nd,nd))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wDrjIrN543Om","colab_type":"text"},"cell_type":"markdown","source":["### foolish-loop"]},{"metadata":{"id":"BblK9ogAoIvK","colab_type":"text"},"cell_type":"markdown","source":["あまり効率の良い方法ではないですが(注)、単純に100万回のループを繰り返してみましょう。\n","\n","さすがにちょっと待たされます。\n","\n","`time()`関数で現在時刻がわかるので計算前後の時刻を引き算すれば何秒かかったかをラフに測ることができます。"]},{"metadata":{"id":"qjGBxjt7S1vO","colab_type":"code","outputId":"b1dfedf3-e5b1-4ae6-e893-ea506a7319e9","executionInfo":{"status":"ok","timestamp":1551320965399,"user_tz":-540,"elapsed":27650,"user":{"displayName":"Naoaki ONO","photoUrl":"https://lh4.googleusercontent.com/-noyv8C6AI_A/AAAAAAAAAAI/AAAAAAAAAEo/YuSJL9LtK-0/s64/photo.jpg","userId":"13379272366422381316"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import time\n","\n","yyy = np.zeros(nn, dtype=np.float)\n","t1 = time.time() \n","for aa in range(nn):\n","  tmp = np.matmul(xxx[aa,:], www)\n","  yyy[aa] = np.mean(tmp)\n","t2 = time.time() \n","print(t2-t1, \"secs\")"],"execution_count":11,"outputs":[{"output_type":"stream","text":["23.887269973754883 secs\n"],"name":"stdout"}]},{"metadata":{"id":"StoRCwmx5Msi","colab_type":"text"},"cell_type":"markdown","source":["### TensorFlow session"]},{"metadata":{"id":"6_ZY8i2Zof3B","colab_type":"text"},"cell_type":"markdown","source":["次にTensorFlowを使って計算してみましょう。\n","\n","まず、TensorFlowでの計算手順を保存するためのsessionという環境を用意します。\n","\n","これは、基本的には最初に一度だけ実行すれば問題ありません。"]},{"metadata":{"id":"WxV47ygUhECx","colab_type":"code","colab":{}},"cell_type":"code","source":["if not \"sess\" in globals():\n","  sess = tf.InteractiveSession()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QhIpE9zZo4cl","colab_type":"text"},"cell_type":"markdown","source":["次に、計算手順を定義します。\n","\n","入力されるデータの形と、データに適用される一連の関数を与えます。\n","\n","定義が終わったら一度「初期化」を行います。\n","\n","この段階で`output1`を見てもまだ数値は出てきません。\n","「`tf.Tensor`」なるオブジェクトが定義されているだけです。"]},{"metadata":{"id":"o7ZPnXdPUSuo","colab_type":"code","outputId":"95638d6f-9c4e-4650-e7ef-196f733e040a","executionInfo":{"status":"ok","timestamp":1551320965404,"user_tz":-540,"elapsed":24410,"user":{"displayName":"Naoaki ONO","photoUrl":"https://lh4.googleusercontent.com/-noyv8C6AI_A/AAAAAAAAAAI/AAAAAAAAAEo/YuSJL9LtK-0/s64/photo.jpg","userId":"13379272366422381316"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["\n","input1 = tf.placeholder(dtype=tf.float64, shape=(None, nd))\n","tfwww = tf.Variable(www,dtype=tf.float64)\n","layer1 = tf.tensordot(input1, tfwww, axes=[1,0])\n","\n","output1 = tf.reduce_mean(layer1, axis=1)\n","\n","sess.run(tf.global_variables_initializer())\n","output1\n"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor 'Mean_1:0' shape=(?,) dtype=float64>"]},"metadata":{"tags":[]},"execution_count":13}]},{"metadata":{"id":"-5qLEsLaqDoe","colab_type":"text"},"cell_type":"markdown","source":["さてお待たせしました。ようやく計算できます。\n","\n","`output1`の計算結果を得るために、`eval()`という関数を適用します。\n","\n","今回、この`output1`の計算には引数となる入力データとして`input1`が使われているので、\n","ここに実際のデータを与える必要があります。\n","\n","入力データの\"変数名\"と与える値をペアにした辞書オブジェクトの形式で与えるので\"feed_dict\"と呼ばれています。\n","\n","今回は先ほど生成した乱数の配列`xxx`を使うので、引数は`feed_dict = {input1: xxx}`\n","となります。\n","\n"]},{"metadata":{"id":"_OqUzqrRpG4A","colab_type":"code","outputId":"889062de-efbd-4f9c-9052-853f6a35c5c7","executionInfo":{"status":"ok","timestamp":1551320965692,"user_tz":-540,"elapsed":23019,"user":{"displayName":"Naoaki ONO","photoUrl":"https://lh4.googleusercontent.com/-noyv8C6AI_A/AAAAAAAAAAI/AAAAAAAAAEo/YuSJL9LtK-0/s64/photo.jpg","userId":"13379272366422381316"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["t1 = time.time() \n","result1 = output1.eval(feed_dict={input1: xxx})\n","t2 = time.time()\n","print(t2-t1, \"secs\")"],"execution_count":14,"outputs":[{"output_type":"stream","text":["0.21695971488952637 secs\n"],"name":"stdout"}]},{"metadata":{"id":"fJrxuPxuxdfI","colab_type":"text"},"cell_type":"markdown","source":["最適化された関数が実行されるので、先ほどより何十倍か早くなっています。\n"," \n","Google Colaboratoryでは太っ腹なことにGPUやTPUを無料で利用できます。\n","ページ上部の「ラインタイム」メニューから「ランタイムのタイプを変更」を選択し、「ハードウェアアクセラレータ」の項目から\"GPU\"や\"TPU\"を選択します（セッションは自動的にリセットされます）。\n","\n","上で行なった計算ぐらいだとあまり差はでないかもしれませんが、深層学習のような場合にはデータ量に応じてGPUあるいはTPUをアクティブにしておくと実行時間がだいぶ早くなります。"]},{"metadata":{"id":"ABEzLhM8y-oQ","colab_type":"text"},"cell_type":"markdown","source":["ちなみにオブジェクトに`eval()`関数を適用する代わりに`sess.run()`関数を使ってTensorFlowオブジェクトを評価しても同じように結果を取得できます。\n","\n","複数のオブジェクトの計算結果をまとめて求めたい場合などはこちらの方が便利です。"]},{"metadata":{"id":"YUbSrTtSyjrj","colab_type":"code","outputId":"5e156da3-44d9-4d5d-d8f3-946af5462264","executionInfo":{"status":"ok","timestamp":1551321295684,"user_tz":-540,"elapsed":1307,"user":{"displayName":"Naoaki ONO","photoUrl":"https://lh4.googleusercontent.com/-noyv8C6AI_A/AAAAAAAAAAI/AAAAAAAAAEo/YuSJL9LtK-0/s64/photo.jpg","userId":"13379272366422381316"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["t1 = time.time() \n","res_layer1, res_out1 = sess.run((layer1, output1), feed_dict={input1: xxx})\n","t2 = time.time()\n","print(t2-t1, \"secs\")"],"execution_count":15,"outputs":[{"output_type":"stream","text":["0.7161087989807129 secs\n"],"name":"stdout"}]},{"metadata":{"id":"0w0d1e0Fr5pY","colab_type":"text"},"cell_type":"markdown","source":["補足：上の例では引数であるinput1が比較的すぐにoutput1の計算に使われていますが、ニューラルネットの計算では最後の値を得るために何段階も、何十段階もの関数が必要になることはざらにあります。\n","\n","そのような場合でも、直接間接を問わず出力結果に影響がある入力データを全てこのfeed_dictのリストとして渡してあげる必要があります（逆に依存する入力データがないようなオブジェクトの場合にはfeed_dictは空でも構いません）"]},{"metadata":{"id":"S1cJ-hkFwQ_p","colab_type":"text"},"cell_type":"markdown","source":["### バッチ入力\n","\n","実際のニューラルネットの学習では、入力データの数が膨大になる場合がしばしばあります。\n","\n","そのような場合には入力データを「バッチ」に分割して逐次的に計算することもあります。\n","\n","単純に頭から順に`num_batch`個ずつデータを入力してもいいのですが、順番の偏りによるアーティファクトを避けるために繰り返しの度にランダムにシャッフルするのが一般的です。\n","\n","バッチサイズは大きめにする方が計算効率は良くなりますが、GPUのメモリなどの限界もあるので100前後にすることが多いでしょうか。"]},{"metadata":{"id":"S2WE-wQJUU8p","colab_type":"code","outputId":"dc0977df-4723-44f7-e97b-e9a1eb92e974","executionInfo":{"status":"ok","timestamp":1551321301648,"user_tz":-540,"elapsed":752,"user":{"displayName":"Naoaki ONO","photoUrl":"https://lh4.googleusercontent.com/-noyv8C6AI_A/AAAAAAAAAAI/AAAAAAAAAEo/YuSJL9LtK-0/s64/photo.jpg","userId":"13379272366422381316"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["nb = 10000\n","t1 = time.time() \n","for aa in range(nn//nb):\n","  output1.eval({input1: xxx[(0+nb*aa):(nb+nb*aa),:]})\n","t2 = time.time() \n","print(t2-t1, \"secs\")"],"execution_count":16,"outputs":[{"output_type":"stream","text":["0.29515886306762695 secs\n"],"name":"stdout"}]},{"metadata":{"id":"njqHwLXeyDgz","colab_type":"text"},"cell_type":"markdown","source":["### 注）Numpyの場合\n","\n","正直なところを言えばこの程度の計算ならばTensorFlowでなくてもnumpyライブラリだけでもそこそこ高速に計算できます。"]},{"metadata":{"id":"tC8405Chgcac","colab_type":"code","outputId":"ca300254-50c4-4a17-9105-d6adb233bc1c","executionInfo":{"status":"ok","timestamp":1551321308582,"user_tz":-540,"elapsed":2333,"user":{"displayName":"Naoaki ONO","photoUrl":"https://lh4.googleusercontent.com/-noyv8C6AI_A/AAAAAAAAAAI/AAAAAAAAAEo/YuSJL9LtK-0/s64/photo.jpg","userId":"13379272366422381316"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["t1 = time.time() \n","tmp = np.tensordot(xxx, www, axes=[1,0])\n","np.mean(tmp, axis=0)\n","t2 = time.time() \n","print(t2-t1, \"secs\")"],"execution_count":17,"outputs":[{"output_type":"stream","text":["1.7444629669189453 secs\n"],"name":"stdout"}]},{"metadata":{"id":"Lb-aQsAH9Nqu","colab_type":"text"},"cell_type":"markdown","source":["TensorFlowには行列やテンソル、畳み込みやバックプロパゲーションをはじめとするニューラルネットワークの計算に使われるさまざまな関数と、実行結果の可視化や分析のためのツール群が用意されています。\n","\n","現在も開発が活発であるのは頼もしいのですが、仕様がしょっちゅう変わるのが頭の痛いところではあります。"]},{"metadata":{"id":"XQAnwttw97I4","colab_type":"text"},"cell_type":"markdown","source":["[次のノートを開く](https://colab.research.google.com/github/naono-git/colaboratory/blob/master/note_03_hello_NN.ipynb)"]},{"metadata":{"id":"ODvS4eRzls-w","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}